%\documentclass[journal]{vgtc}                % final (journal style)
%\documentclass[review,journal]{vgtc}         % review (journal style)
%\documentclass[widereview]{vgtc}             % wide-spaced review
\documentclass[preprint,journal]{vgtc}       % preprint (journal style)
%\documentclass[electronic,journal]{vgtc}     % electronic version, journal

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier. Further, ``electronic'' includes
%% hyperreferences for more convenient online viewing.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Please note that the use of figures other than the optional teaser is 
%% not permitted on the first page of the journal version.  Figures should 
%% begin on the second page and be in CMYK or Grey scale format, 
%% otherwise, colour shifting may occur during the printing process.  
%% Papers submitted with figures other than the optional teaser on the
%% first page will be refused.

%% These three lines bring in essential packages: ``mathptmx'' for Type 1
%% typefaces, ``graphicx'' for inclusion of EPS figures. and ``times''
%% for proper handling of the times font family.
\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{times}

%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

%% This turns references into clickable hyperlinks.
\usepackage[bookmarks,backref=true,linkcolor=black]{hyperref} %,colorlinks
\hypersetup{
  pdfauthor = {},
  pdftitle = {},
  pdfsubject = {},
  pdfkeywords = {},
  colorlinks=true,
  linkcolor= black,
  citecolor= black,
  pageanchor=true,
  urlcolor = black,
  plainpages = false,
  linktocpage
}

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{0}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% allow for this line if you want the electronic option to work properly
\vgtcinsertpkg

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in IEEE Transactions on Visualization and Computer Graphics.}

%% Paper title.

\title{InterventionViz: A Visual Analysis of Behavior Changing Event Dynamics}

%% This is how authors are specified in the journal style

%% indicate IEEE Member or Student Member in form indicated below
\author{T. Murray \textit{Student Member, IEEE}, D. Spruijt-Metz, E. Hekler, A. Raij}
\authorfooter{
%% insert punctuation at end of each item
\item
 T. Murray is with the University of South Florida. E-mail: tylarmurray@mail.usf.edu.
\item
 D. Spruijt-Metz is with .
\item
 E. Hekler is with .
\item
 A. Raij is with the University of South Florida.
}

%other entries to be set up for journal
\shortauthortitle{Biv \MakeLowercase{\textit{et al.}}: InterventionViz}
%\shortauthortitle{Firstauthor \MakeLowercase{\textit{et al.}}: Paper Title}

%% Abstract section.
\abstract{
With the advent of research-grade wearable sensor suites and increasingly ubiquitous human-computer interface comes the opportunity for a new generation of behavioral theory and behavior change methodologies. 
Just-in-time interventions (JITIs) designed to optimize a subjects behavior based on their momentary context are under exploration as a potentially powerful ally for practitioners and commercial behavior health applications. 
Analysis of the effect an intervention has on a target behavior, however, is a complex task not well handled by current methods. 
In this work we explore the application of aggregated time-series visualization techniques to aid analysis of intervention event effects with emphasis on the dynamics of participant response to intervention. 
To highlight the strengths and caveats of the techniques employed, data from two trial studies of physical activity interventions (n=11, n=10) and one empirical control dataset (n=1) are utilized. 
The insights presented in this work offer a foundation for future visualization research addressing this problem and as a guide for behavioral scientists in need of more novel methods of analysis.
} % end abstract

%% Keywords that describe your work. Will show as 'Index Terms' in journal
%% please capitalize first letter and insert punctuation after last keyword
\keywords{Radiosity, global illumination, constant time}

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CCScat'' command takes four arguments.

\CCScatlist{ % not used in journal version
 \CCScat{K.6.1}{Management of Computing and Information Systems}%
{Project and People Management}{Life Cycle};
 \CCScat{K.7.m}{The Computing Profession}{Miscellaneous}{Ethics}
}

%% Uncomment below to include a teaser figure.
   \teaser{
   \centering
   \includegraphics[width=16cm]{./img/teaser}
   \caption{Sum of step counts following an intervention event shows event response dynamics.}
  }

%% Uncomment below to disable the manuscript note
%\renewcommand{\manuscriptnotetxt}{}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title block.

%% the only exception to this rule is the \firstsection command
\firstsection{Introduction}

\maketitle

%% \section{Introduction} %for journal use above \firstsection{..} instead

TODO: refs are from ubicomp submission

The confluence of pervasive sensing, machine learning, network access, and computation is facilitating new approaches to improving behavioral choices.
These systems can detect behaviors and psychological states such as stress\cite{chang2011,lu2012}, physical activity\cite{li2010,emken2012}, social interaction\cite{wyatt2011}, and smoking\cite{sazonov2011}, automatically and, in some cases, in real-time. 
These data provide new opportunities for the human-computer interaction (HCI), behavioral science, and other related communities to develop user interfaces for mobile behavioral interventions that help users make better in the moment behavioral choices related to health\cite{klasnja2012,nahum2012}, productivity\cite{ho2005,sohn2005,jewell2011}, personal finance\cite{gallego2012}, and environmental stewardship.\cite{elliott2012}
New methods for evaluating these behavioral interventions remain underexplored and conventional methods of analysis do not offer the level of detail needed to explore the implicit dynamics of just-in-time, interactive, or adaptive interventions.

Current theories of behavior appear inadequate to inform state-of-the-art intervention development /cite{Riley2011}, but current methods of intervention analysis are limited in their ability to inform the development of state-of-the-art behavioral theories. 
In addition to metrics of success, behavioral theorists need tools to help understand the dynamics of behavioral responses to a stimulus. 
We present methods for exploring these dynamical responses through data visualization.

\subsection{Current Intervention Methods}
TODO: EXAMPLES OF JITAI (Just In Time Adaptive Interventions) ANALYSIS and HOW METHODS FALL SHORT

\subsection{Related Event-based Time Series Visualization}
TODO: INSPIRATION TAKEN FROM EXISTING VIZ WORK


\subsection{Example Application: Physical Activity}
As an example application to demonstrate the strengths of the proposed visual analytics we analyze two empirical datasets with a minute-level metric of physical activity level and intervention events delivered throughout a period of >8 days. 
In both studies interventions were delivered with the intent of increasing subjects’ physical activity, and responses to interventions varied between participants and delivery contexts. 
In addition to this data, a control dataset with known intervention responses is included for comparison.

\subsubsection{mAvatar Study}
An alternating treatment design is used to examine subject behavior over a period of 8+ days in order to test the effect size of an avatar-based “live wallpaper” deployed on Android phones. 
Subjects (n=11) aged 11-14 were exposed to a simple, animated cartoon avatar on their mobile device showing alternating levels of physical activity. 
Each day the avatar would either be active (playing basketball, running, bicycling) or sedentary (watching TV, on a computer, or playing video games). 
Fitbit One electronic pedometers were used to estimate subject levels of physical activity via step count. 

\subsubsection{KnowMe Study}
In this study ten teenagers were asked to carry a smartphone and wear an accelerometer and a heart rate monitor (PAdevice??) for 3 days. 
Physical activity was measured continuously and was monitored in real time. 
When a subject had been continuously sedentary for two hours, a personalized SMS text message was sent to their phone. 
Each text message is manually crafted to prompt the subject to be more physically active.

MORE DETAILS NEEDED

\subsubsection{Control Dataset}
The control dataset is the result of manual recording of one subject undergoing an imaginary, very potent intervention. 
Whenever the subject was at his desk a random timer was set for an interval ranging from 10 to 120 minutes. 
When the timer went off, the time was logged and the subject intentionally increased his level of physical activity for a period of no less than 5 minutes. 
Step counts were recorded throughout the duration of the two-week study period using a fitbit one electronic pedometer.

\section{Design}
Existing “macro-scale” methods can determine if an intervention has a significant influence over our target behavior, but it does not give much insight into how the event has an effect over time. 
The dynamic response to the intervention has only recently become available for study thanks to increasingly ubiquitous wearable sensor technology, and so conventional methods have dealt with low-frequency outcome measures with clever study design.
Now that we can measure outcomes at much higher frequencies, methods which leverage this additional information should be adopted.

The dynamic response of the targeted behavior leading up to and following the event tells us much  more about how this effect begins and fades over time. 
A deeper look into the shape of the signal following our event may even reveal a significant effect overlooked by our previous analysis, and much more quantitative behavioral models become possible. 

\subsection{Highlighting Event Dynamics}
The dynamics surrounding a particular event are most commonly shown using a time series. 
The instance or span of the event is marked on the time-axis and the value of the behavioral measure (physical activity in this case) is encoded in the height at each point in time. 
We can describe several idealized intervention types based on behavioral theory using this common visualization paradigm.

\begin{figure}
\centering
\includegraphics[width=0.6\columnwidth]{./img/exampleDynamicSignals.png}
\caption{Theoretical responses to an intervention (adapted from \cite{glass1975}).}
\label{fig:exampleSignals}
\end{figure}

Figure \ref{fig:exampleSignals} shows the case where an event instantaneously causes permanent change in the target behavior, but in the many cases the intervention will have a temporary effect on the target behavior and will have some delay before setting in. 

\begin{figure}
\centering
\includegraphics[width=0.6\columnwidth]{./img/exampleDynamicComplications.png}
\caption{Level-change responses with delay and decay (adapted from \cite{glass1975}).}
\label{fig:exampleComplications}
\end{figure}

These intervention response dynamics as shown in figure \ref{fig:exampleComplications} are critically important for just-in-time adaptive intervention developers, but are largely unaddressed in current theory.

\subsection{Event-time Alignment}

\begin{figure}
\centering
\includegraphics[width=0.45\columnwidth]{./img/perfect_intervention_individual_events.png}
\includegraphics[width=0.45\columnwidth]{./img/perfect_intervention.png}
\caption{Comparison of all event responses (left) to average response (right) surrounding the control dataset intervention.}
\label{fig:interventionAverage}
\end{figure}	

Figures \ref{fig:exampleSignals} and \ref{fig:exampleComplications} give us sense of what an intervention should look like, but in reality individual variations in context completely mask the often small effect of an intervention (see Figure \ref{fig:interventionAverage} (left)). 
This is a familiar problem with a familiar solution. 
By time-shifting our data view so that each intervention event falls at t=0 in a time-series, we can average the series together in order to identify effects which are common between all events.
Aggregated measurements surrounding each event begin to give a better picture of the latency and delay of the response.

This approach can be taken for all events in one subject's time series to characterize that subject, or can be applied across subjects to characterize a more generalized response to the intervention.


Figure \ref{fig:interventionAverage} makes clear the value of this method for drawing general conclusions from a set of seemingly random data.
When looking at all events individually (figure \ref{fig:interventionAverage} left), it is difficult to spot any pattern in the series.
One notable event seems to stand above the rest from 20-60min following the intervention, and a cursory glance at this visual might lead one to believe that this intervention was only effective in that one instance.
When averaging across all event responses, however, a clear, significant response is evident (figure \ref{fig:interventionAverage} right).

As expected, figure \ref{fig:interventionAverage} shows the control intervention to be quite effective at increasing the step count.
The additional y-axis showing the mean and standard deviation of the series is included to give an increased sense of the significance of this effect relative to data which may be out of frame.

\subsection{Stacking}
To improve upon figure \ref{fig:interventionAverage}, individual events can be shown on the graph and stacked. This yields the same shape, and the y-axis can be easily normalized to match our average series by dividing by the number of events.
While still “averaging out” random contextual influences, this visual also provides indication that the average result is not due to one outlier event, enables easy spotting of missing data or faulty sensors, and gives some indication of the number of events considered.


\begin{figure}
\centering
\includegraphics[width=0.45\columnwidth]{./img/knowMe_60m_lines.png}
\includegraphics[width=0.45\columnwidth]{./img/knowMe_60m_bars.png}
\caption{Comparison of knowMe average lines and stacked bars.}
\label{fig:knowMeCompare}
\end{figure}

Figure \ref{fig:knowMeCompare} shows the difference between a plot of various average response lines and the stacked area plot.
The linegraph allows for identification of unqiue individuals (such as red, light blue TODO: mark these and reference by marker not color), but the stackplot better highlights the overall effect and also shows the number of events considered.
Another key difference between these two approaches is the proporitonate weighting of subjects into the global effect display. The line-graph approach considers each subject equally regarless of the number of events recorded of that subject, whereas the stackplot considers the events equally and thus each subject's contribution is weighted by the number of events recorded. 

Figure \ref{fig:knowMeCompare} shows an increase in heart-rate following the delivery of a physical-activity-suggesting sms message. 
Though the behavioral measure differs greatly from that used in the control dataset and \ref{fig:interventionAverage}, a comparison of the y-values in terms of standard deviation also reveals that this effect is less extreme than the control intervention. 

The deviation from the mean as measured relative to the standard deviation gives a sense of how unlikely the signal is to be a random artifact, but methods for evaluating the statistical likelyhood of observing a particular shape are not covered here.

\subsection{Controlling for Intervention Delivery Context}
In some cases introducing a “control event” against which to compare the experimental event can help isolate the intervention from the context in which it is delivered. 
For instance, an intervention delivered on a mobile device is always delivered within the context of phone interaction.
That is, the user is always using the phone when the intervention is delivered. 
It is possible that "using the phone" has it's own unique effect on the behavioral measure. 
Thus, using "phone use" events as a baseline against which to compare "phone use and intervention delivery" strengthens the chance that the observed effect is a result of the intervention itself and not the result of frequently concurrent contextual forces.
For example, in the control dataset, random points in time when the subject was at his desk can serve as the control event against which to compare the experimental "intervention" event.

To represent this visually we return to the use of line averages due to the confounding nature of negatively-valued bars in stacked graphs.

TODO: fig line graph of controlData avg(intervention)-avg(control)


\subsection{Comparing Event Types}
Aforementioned methods used to provide a contextual baseline of comparison for events can also be applied to allow for a comparison between two event types. 
The mAvatar dataset contains two types of intervention which may be interesting to compare: 1) active-avatar viewing, 2) sedentary-avatar viewing.
In this case, the two event types are theoretically opposite in effect, meaning that the sedentary-avatar effect should resemble a mirrored version of the active-avatar effect.
Furthermore, a comparison should thus allow for even better isolation of the behavioral response to the intervention.

\begin{figure}
\centering
\includegraphics[width=0.9\columnwidth]{./img/mAvatar_difference_events.png}
\caption{Active-event series average minus sedentary-event series average. (average shown as bold)}
\label{fig:mAvatarDifference}
\end{figure}

Figure \ref{fig:mAvatarDifference} doesn't quite show the dramatic effect a researcher might hope for on average, but the individual participant series suggest that there are interesting subgroups within our data.

TODO: talk about the subgroups, label the series.

\subsection{Dealing With Overlapped Data Frames}
When looking at data surrounding an event, we must be cognizant of how instances of the same event at another time may effect our data. For instance, if our analysis targets the 30min following an event, and the event frequently occurs at 10m intervals, the overlapping signals will create unwanted artifacts.

TODO: show simple example with simple bump looks like periodic decay if another event 10m later occurs frequently. 

Figure 47 shows a comparison between data retrieved using the two methods of analysis: no overlap vs overlap ignored. 
Allowing no overlap between events helps ensure that multiple interventions effects do not skew the data, but ignoring these data can drastically reduce data sample if large times following the event are used. 
This summary of step counts following an avatar view event (either sedentary or active) gives a baseline to which we can compare active-avatar and sedentary-avatar views.


\section{Conclusion}
The presented visualization methods allow for more detailed analysis of how a subject’s behavior responds to a stimuli over time. 
These methods, when combined with a computational modeling approach to understanding human behavior may enable behavioral scientists to formulate more accurate and more application-ready theories, leading to more effective behavioral interventions. 

%% if specified like this the section will be committed in review mode
\acknowledgments{
The authors wish to thank A, B, C. This work was supported in part by
a grant from XYZ.}

\bibliographystyle{abbrv}
%%use following if all content of bibtex file should be shown
%\nocite{*}
\bibliography{template}
\end{document}

